import numpy as np
import ipdb as pdb
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import scipy.ndimage.filters as fi
import os
import time
import scipy
import random
import struct
import itertools
import sys
sys.path.append("../../1.VGG_triplet-train/2.vgg_prepare_py")
import prepare_data as similPrepareData
import params_volume

random.seed(201605)
np.random.seed(201610)


grid_D = params_volume.__grid_D_4train
## N = grid_D**3
""" load all the camera POs into a np.float64"""
def load_all_cameraPO_files_f64(view_list = params_volume.__view_set):
    cameraPOs_npf64 = np.zeros((view_list[-1]+1,3,4),dtype=np.float64)
    for n in view_list:
        file_name = params_volume.__camera_po_txt_fld+'pos_{:03}.txt'.format(n)
        cameraPOs_npf64[n] = np.loadtxt(file_name,dtype=np.float64,delimiter = ' ')
    return cameraPOs_npf64

def load_model_meanIMG(modelIndx):
    ##preload all the rectified imgs of the model: modelIndx
    rectified_img_folder = params_volume.__model_imgs_fld+'scan'+str(modelIndx)+'/'
    file_list = os.listdir(rectified_img_folder)
    # if the viewIndx is start from 1, the 0th row of model_imgs = []
    model_imgs = [[None for _ in range(1)] for _ in range(len(file_list)+1)]
    for file in file_list:
        viewIndx = int(file.split('_')[1])
        # if file.split('_')[2] == 'mean.jpg':
        light_cond = 0
        model_imgs[viewIndx][light_cond] = scipy.misc.imread(rectified_img_folder+ file)
    ##img_shape = model_imgs[1][0].shape
    ##img_scope_wh = [img_shape[1],img_shape[0]]
    print('rectified imgs of indx: {} are loaded'.format(modelIndx))
    return model_imgs


def load_model_meanIMG_aslist(modelIndx):
    ##preload all the rectified imgs of the model: modelIndx
    rectified_img_folder = params_volume.__model_imgs_fld+'scan'+str(modelIndx)+'/'
    file_list = os.listdir(rectified_img_folder)
    # if the viewIndx is start from 1, the 0th row of model_imgs = []
    model_imgs = [[None for _ in range(1)] for _ in range(len(file_list)+1)]
    for file in file_list:
        viewIndx = int(file.split('_')[1])
    #    if file.split('_')[2] == 'mean.jpg':
        light_cond = 0
        model_imgs[viewIndx][light_cond] = scipy.misc.imread(rectified_img_folder+ file)
    print('rectified imgs of indx: {} are loaded'.format(modelIndx)) 
    return model_imgs


def load_model_meanIMG_asnp(modelIndx):
    ##preload all the rectified imgs of the model: modelIndx
    rectified_img_folder = os.path.join(params_volume.__model_imgs_fld, 'scan'+str(modelIndx))
    model_imgs_np = None
    
    file_list = os.listdir(rectified_img_folder)
    ## if the viewIndx is start from 1, the 0th row of model_imgs = []
    for i, viewIndx in enumerate(params_volume.__view_set):
        img_path = os.path.join(rectified_img_folder, 'rect_{:03}.png'.format(viewIndx))
        img = scipy.misc.imread(img_path)
        if i==0:
            model_imgs_np = np.zeros((max(params_volume.__view_set)+1,)+ img.shape, dtype=np.uint8)
        model_imgs_np[viewIndx] = img
    print('loaded img ' + rectified_img_folder)
    return model_imgs_np


def load_modellist_meanIMG(modelIndx_list):
    """to index the imgs of perticular nth model, just use modellist_imgs[n]"""
    modellist_imgs = [None for _ in range(max(modelIndx_list)+1)] ## only the position of indexes in the modelIndx_list are non-None
    for n in modelIndx_list:
        # model_imgs_npy_file = params_volume.__model_imgs_npz_fld+'{}.npz'.format(n)
        # if os.path.exists(model_imgs_npy_file): 
        #     modellist_imgs[n] = np.load(model_imgs_npy_file)['arr_0']
        # else:
        modellist_imgs[n] = load_model_meanIMG_asnp(n)
        print('rectified imgs of indx: {} are loaded'.format(n))
    return modellist_imgs


def load_modellist_densityCube_aslist(modelIndx_list):
    """
    load the density cubes' txt representing the surface and generated by pcl
    return two lists, the param list and the data list
    """
    modellist_densityCubes_param = [None for _ in range(max(modelIndx_list)+1)] ## only the position of indexes in the modelIndx_list are non-None
    modellist_densityCubes = [None for _ in range(max(modelIndx_list)+1)] ## only the position of indexes in the modelIndx_list are non-None
    modellist_Cubes_visib = [None for _ in range(max(modelIndx_list)+1)]
    N_views = params_volume.__N_view # NO of views to be considered
    for _modelIndx in modelIndx_list:
        densityCubes_fnm = params_volume.__voxelVolume_txt_fld+'output_stl_{:03}.txt'.format(_modelIndx)
        with open(densityCubes_fnm,mode='r') as f:
            lines = f.readlines()
            cubes_param = np.zeros((len(lines), params_volume.__cube_param_N), dtype=np.float64)
            densityCube_s = np.zeros((len(lines), grid_D, grid_D, grid_D), dtype=np.uint8)
            cube_visib = np.zeros((len(lines),N_views,2), dtype=np.uint8)
            for _i, line in enumerate(lines):
                if ';' in line:
                    l, visib = line.split(';')
                    for _v, _visib in enumerate(visib.split(',')[:-1]):
                        if _v >= N_views:
                            break
                        cube_visib[_i,_v] = np.fromstring(_visib, sep=' ', dtype=np.uint8)
                else:
                    l = line
                ## including min_x/y/z & resolution & modelIndx
                cube_param = np.asarray(l.split(',')[0].split(' '),dtype=np.float64)
                cubes_param[_i] = np.append(cube_param,_modelIndx)
                ## convert each line into an array, whose 4D row presents a 3D voxel's sparse density
                sparsexyz = np.asarray([_l.split(' ') for _l in l.split(',')[1:-1] ], dtype=np.uint16) # assume x/y/z/T will be all uint 
                densityCube = np.zeros((grid_D,grid_D,grid_D), dtype=np.uint8)
                if sparsexyz.size != 0:
                    X, Y, Z, T = sparsexyz[:,0], sparsexyz[:,1], sparsexyz[:,2], sparsexyz[:,3]
                    densityCube[X,Y,Z] = T            
                densityCube_s[_i] = densityCube

            modellist_densityCubes_param[_modelIndx] = cubes_param
            modellist_densityCubes[_modelIndx] = densityCube_s
            modellist_Cubes_visib[_modelIndx] = cube_visib
                
            if params_volume.__visualize_when_generateData_ON:
                visualize_N_densities_pcl([densityCube_s[0],densityCube_s[1],densityCube_s[2]])
    print 'density Cube files are loaded'
    return modellist_densityCubes_param, modellist_densityCubes, modellist_Cubes_visib           
           
         
def RECONSTR_generate_3DSamples_param_np(modelIndx,resol, D_randcrop, D_center,cube_stride_over_Dsize, BB = None):
    """
    func for RECONSTR
    generate {N_cubes} 3D non-overlapped cubes, each one has {N_cubeParams} dim
    for the cube with size of DxDxD, the valid prediction region is the center part, say, dxdxd
    The default grids of the cube is 32x32x32, i.e. D=32, d can be = 20.
    the param part: check the defination of the 'N_cubeParams'    
    return: 
    Samples_param_np, np{N_cubes, N_cubeParams}
    cube_Dsize, scalar
    """
    cube_Dsize = resol * D_randcrop   # D size of each cube, 
    cube_Center_Dsize = resol * D_center   # D size of each cube's center, 
    cube_stride = cube_Center_Dsize * cube_stride_over_Dsize #/ 2  # the distance between adjacent cubes, 
    ## for the +-300;+-300;400/1000 pair, the first 7W points contain almost nothing.
    x_range, y_range, z_range = params_volume.__reconstr_sceneRange if BB is None else BB.T 
    print('xyz bounding box of the reconstructed scene: {}, {}, {}'.format(x_range, y_range, z_range))
    x_=np.arange(x_range[0], x_range[1], cube_stride).astype(np.float32) #+-300 
    y_=np.arange(y_range[0], y_range[1], cube_stride).astype(np.float32) #+-300 
    z_=np.arange(z_range[0], z_range[1], cube_stride).astype(np.float32) #400,1000    / 600, 800
    x,y,z = np.meshgrid(x_,y_,z_,indexing='ij') ## so that the x,y,z will by aligned with the sample_xyz_indices = np.indices(..)
    N_cubes = x.size
    Samples_param_np = np.zeros((N_cubes,8)) # N_cubeParams = 8
    Samples_param_np[:,0] = x.flatten()
    Samples_param_np[:,1] = y.flatten()
    Samples_param_np[:,2] = z.flatten()
    Samples_param_np[:,3] = resol
    Samples_param_np[:,4] = int(modelIndx)
    # store the xyz_indices of each sample, in order to localize the cube
    sample_xyz_indices = np.indices((x_.size,y_.size,z_.size)) 
    Samples_param_np[:,5] = sample_xyz_indices[0].flatten()
    Samples_param_np[:,6] = sample_xyz_indices[1].flatten()
    Samples_param_np[:,7] = sample_xyz_indices[2].flatten()
    
    return Samples_param_np, cube_Dsize
    
           
def RECONSTR_select_valid_pts_in_cube(predict, rgb_3D, param):
    """
    only reserve the center part of the cube, because the boarder of our prediction is not accurate.
    
    predict: {N,1,grid_D,grid_D,grid_D}
    rgb_3D: {N,3,grid_D,grid_D,grid_D}
    param: {N,params_volume.__cube_param_N}
    return: xyz_rgba_np, {N_pts, 4}
    """
    valid_MinMax_indx = [(params_volume.__D_randcrop-params_volume.__D_center)/2, (params_volume.__D_randcrop-params_volume.__D_center)/2 + params_volume.__D_center - 1]
    valid_pts_indx = np.argwhere(predict>=1) 
    center_pts_indx = ((valid_pts_indx >= valid_MinMax_indx[0]) & (valid_pts_indx <= valid_MinMax_indx[1]))[:,3:].all(axis=1) # make sure all the xyz=n_xyz[-3:] are inscope
    valid_pts_indx = valid_pts_indx[center_pts_indx]
    N_pts = valid_pts_indx.shape[0]
    RGB_uint8 = rgb_3D.astype(np.uint8)
    A = np.asarray(254, dtype=np.uint8)        
    xyz_rgba_np = np.zeros((N_pts, 4))
    for i in xrange(N_pts):
        # valid_pts_indx: {N_pts, predict.ndim}
        n, _, ix, iy, iz = valid_pts_indx[i]
        x_min, y_min, z_min, resol, modelIndx = param[n][:5]
        x, y, z = x_min+ix*resol, y_min+iy*resol, z_min+iz*resol
        RGB = RGB_uint8[n,:,ix,iy,iz]
        ## thanks to: 'http://www.pcl-users.org/How-to-convert-from-RGB-to-float-td4022278.html'
        rgba = struct.unpack('f', chr(RGB[2]) + chr(RGB[1]) + chr(RGB[0]) + chr(A))[0]        
        xyz_rgba_np[i] = x, y, z, rgba
    
    return xyz_rgba_np

def RECONSTR_save_pcd(xyzrgba_stack, model_folder, filename):
    f = open(model_folder+filename,'w')
    header = """# .PCD v.7 - Point Cloud Data file format
VERSION .7
FIELDS x y z rgb
SIZE 4 4 4 4
TYPE F F F F
COUNT 1 1 1 1
WIDTH {0}
HEIGHT 1
VIEWPOINT 0 0 0 1 0 0 0
POINTS {0}
DATA ascii\n""".format(xyzrgba_stack.shape[0])
    #np.save(open(save_dataset_folder+str(modelIndx).zfill(3)+'_'+mode+'_xyz.data', "w" ), xyz)
    f.write(header)
    for l in range(0,xyzrgba_stack.shape[0]):
        f.write('{} {} {} {}\n'.format(xyzrgba_stack[l,0],xyzrgba_stack[l,1],xyzrgba_stack[l,2], xyzrgba_stack[l,3]))
    f.close()
    print("save {} points to: {}{}".format(xyzrgba_stack.shape[0], model_folder,filename))


def threshold(xlist, min, max):
    output = []
    for x in xlist:
        x[x<min] = min
        x[x>max] = max
        output.append(x)
    return output


def save_tmp_visual_file(x,y,z,R,G,B,density):
    tmp_file_nm = '{:1.8f}.tmp'.format(time.time())
    if not (x.size==y.size==z.size==density.size):
        print 'error: size of x/y/z/density should be the same'
        return None
    if not os.path.exists(params_volume.__tempResult_4visual_fld):
        os.makedirs(params_volume.__tempResult_4visual_fld)    
    with open(params_volume.__tempResult_4visual_fld+tmp_file_nm,'w') as f:
        for n in xrange(x.size):
            f.write('{} {} {} {} {} {} {}\n'.format(x[n],y[n],z[n],R[n],G[n],B[n],density[n]))
    return params_volume.__tempResult_4visual_fld+tmp_file_nm+' '
        
        
def visualize_N_densities_pcl(coloredCube_list):
    N_subplt = len(coloredCube_list)
    files_2_visual=' '
    os.system('rm '+params_volume.__tempResult_4visual_fld+'*') # remember to clear the tmp_file_folder frequently    
    for _n, coloredCube in enumerate(coloredCube_list):
        coloredCube = coloredCube.astype(np.uint8)
        if coloredCube.ndim == 1:
            coloredCube = np.reshape(coloredCube, (grid_D,grid_D,grid_D))
        if coloredCube.ndim >= 3:
            coloredCube = coloredCube.squeeze()
            if  coloredCube.ndim == 3: ## DxDxD, the value represents the density
                density = coloredCube
                density, = threshold([density], int(params_volume.__pts_in_voxel_MIN), int(params_volume.__pts_in_voxel_MAX))
                density = density.round() # for visualization, small values like 0.1 can also be shown
                X, Y, Z = density.nonzero()
                T = density[X,Y,Z]       
                R, G, B = T*10, 100+T*10, T*10
            elif coloredCube.ndim == 4: ## ChannelxDxDxD, the value represent the RGB values, in order to visualize, let density = 1
                ##meshgrid: indexing : {'xy', 'ij'}, optional     ##Cartesian ('xy', default) or matrix ('ij') indexing of output.    
                _D = coloredCube.shape[-1]
                #X,Y,Z = np.meshgrid(range(0,_D),range(0,_D),range(0,_D),indexing='ij')                  
                #R,G,B = coloredCube[0],coloredCube[1],coloredCube[2]
                X,Y,Z = coloredCube.any(axis=0).nonzero() # Now, it only show the nonZero parts.
                R,G,B = coloredCube[0,X,Y,Z],coloredCube[1,X,Y,Z],coloredCube[2,X,Y,Z]
                T = np.ones(R.shape, dtype=np.uint8)
                X,Y,Z,R,G,B,T = X.flatten(),Y.flatten(),Z.flatten(),R.flatten(),G.flatten(),B.flatten(),T.flatten()
            else:   
                print 'error: the visualized array\'s shape != 1 or 3'

        files_2_visual += save_tmp_visual_file(X,Y,Z,R,G,B,T.astype(np.uint8))
    
    os.system(params_volume.__visualizer+files_2_visual) 
    print 'visualizer is waiting for enter to continue...'
    raw_input() # wait for 'enter'  


def load_1Ddata():
   
    filenm_train_data_noisy = params_volume.__data_fld+'train_data_noisy.npy'
    filenm_train_data_gt = params_volume.__data_fld+'train_data_gt.npy'
    filenm_val_data_noisy = params_volume.__data_fld+'val_data_noisy.npy'
    filenm_val_data_gt = params_volume.__data_fld+'val_data_gt.npy'
    if os.path.exists(filenm_train_data_noisy) and \
       os.path.exists(filenm_train_data_gt) and \
       os.path.exists(filenm_val_data_noisy ) and \
       os.path.exists(filenm_val_data_gt) :
        print('train val data files exist')
        train_data_noisy = np.load(filenm_train_data_noisy)
        train_data_gt = np.load(filenm_train_data_gt)
        val_data_noisy = np.load(filenm_val_data_noisy)
        val_data_gt = np.load(filenm_val_data_gt)
            
    else:
        print('train val data files don\'t exist')
        train_data_noisy, train_data_gt = read_setof_model_file(params_volume.__train_set)
        #visualize_2_densities(train_data_gt[12],train_data_noisy[12])
        val_data_noisy, val_data_gt = read_setof_model_file(params_volume.__val_set)
        train_data_noisy, train_data_gt, val_data_noisy, val_data_gt = threshold(\
            [train_data_noisy, train_data_gt, val_data_noisy, val_data_gt], int(params_volume.__pts_in_voxel_MIN), int(params_volume.__pts_in_voxel_MAX))
        with open(filenm_train_data_noisy,'w') as f:
            np.save(f,train_data_noisy.astype(np.uint8) )
        with open(filenm_train_data_gt,'w') as f:
            np.save(f,train_data_gt.astype(np.uint8) )
        with open(filenm_val_data_noisy,'w') as f:
            np.save(f,val_data_noisy.astype(np.uint8) )
        with open(filenm_val_data_gt,'w') as f:
            np.save(f, val_data_gt.astype(np.uint8))            
            
    
    return train_data_noisy.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           train_data_gt.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           val_data_noisy.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           val_data_gt.astype(np.float32)/params_volume.__pts_in_voxel_MAX

def save_sparse_csr(filename,array):
    array_sparse = scipy.sparse.csr_matrix(array)
    np.savez(filename,data = array_sparse.data ,indices=array_sparse.indices,
             indptr =array_sparse.indptr, shape=array_sparse.shape )

def load_sparse_csr(filename):
    loader = np.load(filename)
    return scipy.sparse.csr_matrix((  loader['data'], loader['indices'], loader['indptr']),
                         shape = loader['shape']).toarray()

def load_1Ddata_sparse():
    filenm_train_data_noisy = params_volume.__data_fld+'train_data_noisy.npy'
    filenm_train_data_gt = params_volume.__data_fld+'train_data_gt.npy'
    filenm_val_data_noisy = params_volume.__data_fld+'val_data_noisy.npy'
    filenm_val_data_gt = params_volume.__data_fld+'val_data_gt.npy'
    if os.path.exists(filenm_train_data_noisy) and \
       os.path.exists(filenm_train_data_gt) and \
       os.path.exists(filenm_val_data_noisy ) and \
       os.path.exists(filenm_val_data_gt) :
        print('train val data files exist')
        train_data_noisy = load_sparse_csr(filenm_train_data_noisy)
        train_data_gt = load_sparse_csr(filenm_train_data_gt)
        val_data_noisy = load_sparse_csr(filenm_val_data_noisy)
        val_data_gt = load_sparse_csr(filenm_val_data_gt)
            
    else:
        print('train val data files don\'t exist')
        train_data_noisy, train_data_gt = read_setof_model_file(params_volume.__train_set)
        #visualize_2_densities(train_data_gt[12],train_data_noisy[12])
        val_data_noisy, val_data_gt = read_setof_model_file(params_volume.__val_set)
        train_data_noisy, train_data_gt, val_data_noisy, val_data_gt = threshold(\
            [train_data_noisy, train_data_gt, val_data_noisy, val_data_gt], int(params_volume.__pts_in_voxel_MIN), int(params_volume.__pts_in_voxel_MAX))
        with open(filenm_train_data_noisy,'w') as f:
            save_sparse_csr(f,train_data_noisy )
        with open(filenm_train_data_gt,'w') as f:
            save_sparse_csr(f,train_data_gt)
        with open(filenm_val_data_noisy,'w') as f:
            save_sparse_csr(f,val_data_noisy )
        with open(filenm_val_data_gt,'w') as f:
            save_sparse_csr(f, val_data_gt) ## don't save as int, otherwise when reload the data, all the dtype will be int.           
            
    
    return train_data_noisy.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           train_data_gt.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           val_data_noisy.astype(np.float32)/params_volume.__pts_in_voxel_MAX, \
           val_data_gt.astype(np.float32)/params_volume.__pts_in_voxel_MAX


def load_3Ddata(LowResolution = False):
    train_noisy, train_gt, val_noisy, val_gt = load_1Ddata_sparse()
    ##N_voxels = train_gt.shape[-1]
    ##d = int(N_voxels ** (1/3.) + .5) # round, not elegant at all!
    if LowResolution:
        for dataset_stack in [train_noisy, val_noisy]:
            for dataset in dataset_stack:
                randIndx = np.asarray(range(N))
                np.random.shuffle(randIndx)
                dataset[randIndx[:15*N/16]] = 0       
    return [x.reshape((x.shape[0],1)+(grid_D,)*3) for x in [train_noisy, train_gt, val_noisy, val_gt]]
    

#----------------------------------------------------------------------
def map_pixHW_2_uintIDnp(pt_w,pt_h):
    """ 
    used in func: 'colorize_cube' 
    np([21,20,22,21,21]),np([10,11,12,13,13]) ==> np([0,1,2,3,3])
    """
    ##range_w = pt_w.max()-pt_w.min()+1
    ##pixID_value = (pt_h-pt_h.min()) * range_w + (pt_w-pt_w.min())
    ##unique_pixID_value = set(pixID_value)
    ##mapping = {_value:_indx for _indx, _value in enumerate(unique_pixID_value)}
    ##return np.asarray(map(mapping.get, pixID_value),dtype=np.uint16)
    # above version: max_indx = 20K, 
    # below refined version: max_indx = 13K
    ##wh_tupleList = [(w,h) for w, h in zip(pt_w, pt_h)]
    ##wh_tupleList_set=set(wh_tupleList)
    ##mapping = {_wh_tuple:_wh_tuple_indx for _wh_tuple_indx, _wh_tuple in enumerate(wh_tupleList_set)}
    ##return np.asarray(map(mapping.get, wh_tupleList),dtype=np.uint16)
    # above version: because of using list, takes long time
    # below version: only use numpy to implement. Thanks: http://stackoverflow.com/questions/29535341/generate-unique-values-based-on-rows-in-a-numpy-array
    pt_wh_np = np.asarray([pt_w,pt_h]).T
    pt_wh_sort_indx = np.lexsort(pt_wh_np.T)
    pt_wh_sort_diff = np.diff(pt_wh_np[pt_wh_sort_indx], axis=0)
    maskID_sort = np.cumsum(np.append([True],pt_wh_sort_diff.any(axis=1)))
    maskID = np.zeros(pt_wh_sort_indx.shape, dtype=np.uint16)
    maskID[pt_wh_sort_indx] = maskID_sort   
    return maskID

#----------------------------------------------------------------------
def colorize_cube(a_densityCube_param_data, view_set, cameraPOs_np, model_imgs_np, colorize_cube_D=grid_D, visualization_ON=False,\
            return_pixIDmask_cubes_ON = False):
    """ 
    generate colored cubes of a perticular densityCube  
    inputs: a_densityCube_param_data=[cube_param_np, cube_data_np]
    output: [views_N, 3, colorize_cube_D, colorize_cube_D, colorize_cube_D]. 3 is for RGB
    """
    max_h, max_w, _ = model_imgs_np[0].shape
    min_x,min_y,min_z,resol,modelIndx = a_densityCube_param_data[0][:5]
    densityCube = a_densityCube_param_data[1]
    indx_xyz = range(0,colorize_cube_D)
    ##meshgrid: indexing : {'xy', 'ij'}, optional     ##Cartesian ('xy', default) or matrix ('ij') indexing of output.    
    indx_x,indx_y,indx_z = np.meshgrid(indx_xyz,indx_xyz,indx_xyz,indexing='ij')  
    indx_x = indx_x * resol + min_x
    indx_y = indx_y * resol + min_y
    indx_z = indx_z * resol + min_z
    homogen_1s = np.ones(colorize_cube_D**3, dtype=np.float64)
    pts_4D = np.vstack([indx_x.flatten(),indx_y.flatten(),indx_z.flatten(),homogen_1s])
    
    N_views = len(view_set)
    colored_cubes = np.zeros((N_views,3,colorize_cube_D,colorize_cube_D,colorize_cube_D))
    pixIDmask_cubes = np.zeros((N_views,1,D,D,D), dtype=np.uint16) if return_pixIDmask_cubes_ON else None
    # only chooce from inScope views
    # center_pt_xyz1 = np.asarray([grid_D*resol/2 + min_x, grid_D*resol/2 + min_y, grid_D*resol/2 + min_z, 1])
    # center_pt_3D = np.dot(cameraPOs_np,center_pt_xyz1)
    # center_pt_wh = center_pt_3D[:,:-1] / center_pt_3D[:,-1:]# the result is vector: [w,h,1], w is the first dim!!!
    # valid_views = (center_pt_wh[:,0]<max_w) & (center_pt_wh[:,1]<max_h) & (center_pt_wh[:,0]>0) & (center_pt_wh[:,1]>0)      
    # while valid_views.sum() < N_randViews: ## if only n views can see this pt, where n is smaller than N_randViews, randomly choose some more
    #     valid_views[random.randint(1,cameraPOs_np.shape[0]-1)] = True
    # valid_view_list = list(valid_views.nonzero()[0]) ## because the cameraPOs_np[0] is zero, don't need +1 here
    # view_list = random.sample(valid_view_list,N_randViews)    
    
    for _n, _view in enumerate(view_set):
        # perspective projection
        projection_M = cameraPOs_np[_view]  ## use viewIndx
        pts_3D = np.dot(projection_M, pts_4D)
        pts_3D[:-1] /= pts_3D[-1] # the result is vector: [w,h,1], w is the first dim!!!
        pts_2D = pts_3D[:-1].round().astype(np.int32)
        pts_w, pts_h = pts_2D[0], pts_2D[1]
        # access rgb of corresponding model_img using pts_2D coordinates
        pts_RGB = np.zeros((colorize_cube_D**3, 3))
        img = model_imgs_np[_view]  ## use viewIndx
        inScope_pts_indx = (pts_w<max_w) & (pts_h<max_h) & (pts_w>=0) & (pts_h>=0)
        pts_RGB[inScope_pts_indx] = img[pts_h[inScope_pts_indx],pts_w[inScope_pts_indx]]
        colored_cubes[_n] = pts_RGB.T.reshape((3,colorize_cube_D,colorize_cube_D,colorize_cube_D))
        if return_pixIDmask_cubes_ON:
            pts_pixID = map_pixHW_2_uintIDnp(pts_w, pts_h)
            pixIDmask_cubes[_n] = pts_pixID.reshape((1,D,D,D))
        
    if visualization_ON:    
        visualize_N_densities_pcl([densityCube]+[colored_cubes[n] for n in range(0,len(5))])
        

    return colored_cubes, pixIDmask_cubes

    
    

#----------------------------------------------------------------------            
def gen_coloredCubes(selected_viewPairs, occupiedCubes_param, cameraPOs, models_img, visualization_ON = False, \
            occupiedCubes_01=None, return_pixIDmask_cubes_ON=False, colorize_cube_D=grid_D):     
    """
    inputs: 
    selected_viewPairs: (N_cubes, N_select_viewPairs, 2)
    occupiedCubes_param: parameters for each occupiedCubes (N,params)
    occupiedCubes_01: multiple occupiedCubes (N,)+(colorize_cube_D,)*3
    return:
    coloredCubes = (N*N_select_viewPairs,3*2)+(colorize_cube_D,)*3 
    """
    N_select_viewPairs = selected_viewPairs.shape[1]
    N_cubes = occupiedCubes_param.shape[0]
    coloredCubes = np.zeros((N_cubes,N_select_viewPairs*2,3)+(colorize_cube_D,)*3, dtype=np.float32) # reshape at the end

    if return_pixIDmask_cubes_ON:
        pixIDmask_cubes = np.zeros((N_cubes,N_select_viewPairs*2,1)+(colorize_cube_D,)*3, dtype=np.uint16) # reshape at the end
         

    for _n_cube in range(0, N_cubes): ## each cube
        timer_start = time.time()
        occupiedCube_param = occupiedCubes_param[_n_cube]
        if visualization_ON:
            if occupiedCubes_01 is None:
                print 'error: [func]gen_coloredCubes, occupiedCubes_01 should not be None when visualization_ON==True'
            occupiedCube_01 = occupiedCubes_01[_n_cube]
        else:
            occupiedCube_01 = None
        ##randViewIndx = random.sample(range(1,cameraPOs.shape[0]),N_randViews)
            
        model_indx = int(occupiedCube_param[4])

        occupiedCube_param_01 = [occupiedCube_param, occupiedCube_01]
        #(N_cubes, N_select_viewPairs, 2) ==> (N_select_viewPairs*2,). 
        selected_views = selected_viewPairs[_n_cube].flatten() 
        # because selected_views could include duplicated views, this case is not the best way. But if the N_select_viewPairs is small, it doesn't matter too much
        coloredCube, pixIDmask_cube = colorize_cube(a_densityCube_param_data = occupiedCube_param_01, view_set = selected_views, \
                      cameraPOs_np = cameraPOs, model_imgs_np = models_img[model_indx], visualization_ON=visualization_ON, \
                      return_pixIDmask_cubes_ON=return_pixIDmask_cubes_ON, colorize_cube_D=colorize_cube_D)


        # [a,b,c] ==> [a,b,a,c,b,c]
        ##all_pairIndx = ()
        ##for _pairIndx in itertools.combinations(range(0,N_randViews),2):
            ##all_pairIndx += _pairIndx
        ##all_pairIndx = list(all_pairIndx)
        
        # # [a,b,c,d,e,f,g,h,i,j] ==> [a,b,g,c,f,e]
        # all_pairIndx = []
        # for _pairIndx in itertools.combinations(range(0,N_randViews),2):
        #     all_pairIndx.append(_pairIndx)
        # all_pairIndx = random.sample(all_pairIndx, N_select_viewPairs)
        # all_pairIndx = [x for pair_tuple in all_pairIndx for x in pair_tuple] ## [(a,),(a,b),(a,b,c)] ==> [a,a,b,a,b,c]
        
        coloredCubes[_n_cube] = coloredCube
        if return_pixIDmask_cubes_ON:
            pixIDmask_cubes[_n_cube] = pixIDmask_cube
            
    if return_pixIDmask_cubes_ON:
        return coloredCubes.reshape((N_cubes*N_select_viewPairs,3*2)+(colorize_cube_D,)*3), \
               pixIDmask_cubes.reshape((N_cubes*N_viewPairs,1*2,D,D,D))
    else:
        return coloredCubes.reshape((N_cubes*N_select_viewPairs,3*2)+(colorize_cube_D,)*3)





#----------------------------------------------------------------------            
def inScope_check(a_densityCube_param_data, N_inScopeViews, cameraPOs_np, model_imgs_np):
    """ 
    check how many views can observe this cube. If the NO is smaller than N_inScopeViews, return None.
    inputs: a_densityCube_param_data=[cube_param_np, cube_data_np]
    """
    max_h, max_w, _ = model_imgs_np[0].shape
    min_x,min_y,min_z,resol,modelIndx = a_densityCube_param_data[0]
        
    # only chooce from inScope views
    center_pt_xyz1 = np.asarray([grid_D*resol/2 + min_x, grid_D*resol/2 + min_y, grid_D*resol/2 + min_z, 1])
    center_pt_3D = np.dot(cameraPOs_np,center_pt_xyz1)
    center_pt_wh = center_pt_3D[:,:-1] / center_pt_3D[:,-1:]# the result is vector: [w,h,1], w is the first dim!!!
    valid_views = (center_pt_wh[:,0]<max_w) & (center_pt_wh[:,1]<max_h) & (center_pt_wh[:,0]>0) & (center_pt_wh[:,1]>0)      
    if valid_views.sum() < N_inScopeViews:
        return None
    return 0
    
#----------------------------------------------------------------------            
def inScope_Cubes(N_inScopeViews, occupiedCubes_param, cameraPOs, models_img, cubes_visib = None):     
    """
    inputs: 
    N_inScopeViews: scalar, represents threshold of NO. for inScope views
    occupiedCubes_param: parameters for each occupiedCubes (N,params)
    # occupiedCubes_01: multiple occupiedCubes (N,grid_D,grid_D,grid_D)
    return:
    inScope_indices
    # occupiedCubes_param_inScope: filtered
    # occupiedCubes_01_inScope: filtered occupiedCubes (N,grid_D,grid_D,grid_D)
    """
    N_cubes = occupiedCubes_param.shape[0]
    if cubes_visib is None:
        inScope_indices = np.ones((N_cubes), dtype=np.bool)
        for _n_cube in range(0, N_cubes): ## each cube
            occupiedCube_param = occupiedCubes_param[_n_cube]
            ##randViewIndx = random.sample(range(1,cameraPOs.shape[0]),N_randViews)
                
            model_indx = int(occupiedCube_param[4])

            occupiedCube_param_01 = [occupiedCube_param, None]
            inScope_check_ = inScope_check(a_densityCube_param_data = occupiedCube_param_01, N_inScopeViews=N_inScopeViews, \
                          cameraPOs_np = cameraPOs, model_imgs_np = models_img[model_indx])
            if inScope_check_ is None:
                inScope_indices[_n_cube] = False
    else:
        inScope_indices = np.sum(cubes_visib[:,:,1], axis=-1) >= N_inScopeViews
    return inScope_indices
    # if occupiedCubes_01 is None:    
    #     return occupiedCubes_param[inScope_indices], None
    # else:        
    #     return occupiedCubes_param[inScope_indices], occupiedCubes_01[inScope_indices]


#----------------------------------------------------------------------            
def load_gt_asnp(modellist, visualization_ON=False, return_soft_occupancy_ON = False):     
    """
    load train/val_gt, which include the param part and the data part
    the param part: check the defination of the 'params_volume.__cube_param_N'
    the data part: 0/1 indicate whether this subcube can be considered as a surface
    return_soft_occupancy_ON: 
    if False: the gt_01 = 1 if density>1 else 0
    if True: the gt_float = density/density_inCurrentCube.max(); gt_01 = 1 if density > 0.5 else 0.
    """
    models_densityCube_param,models_densityCube, model_Cubes_visib = load_modellist_densityCube_aslist(modellist)
    gt_param, gt_Density = [models_densityCube_param[i] for i in modellist],[models_densityCube[i] for i in modellist]
    gt_visib = [model_Cubes_visib[i] for i in modellist]
    
    gt_param = np.asarray(gt_param).reshape(-1,params_volume.__cube_param_N)
    gt_visib = np.asarray(gt_visib).reshape(-1, params_volume.__N_view, 2)

    normalize_keep_dim0 = lambda x : x/(np.amax(x,axis=(1,2,3),keepdims=True).astype(np.float32))
    gt_float = normalize_keep_dim0(np.asarray(gt_Density).reshape(-1,grid_D,grid_D,grid_D) )
    # gt_01 = np.where(gt_float > 0.5, 1, 0).astype(np.uint8)
    # gt_01 = np.where(gt_float > params_volume.__soft_gt_thresh, 1, 0).astype(np.uint8)
    gt_01 = np.where(np.asarray(gt_Density).reshape(-1,grid_D,grid_D,grid_D) > 1, 1, 0).astype(np.uint8)
    
    del models_densityCube_param,models_densityCube, gt_Density

    if visualization_ON:
        visualize_N_densities_pcl([gt_01[0],gt_01[100]])
    return gt_param, gt_01, gt_float, gt_visib
    

#----------------------------------------------------------------------            
def load_train_val_gt_asnp(visualization_ON=False, return_soft_occupancy_ON = False):     
    """
    load train/val_gt, which include the param part and the data part
    the param part: check the defination of the 'params_volume.__cube_param_N'
    the data part: 0/1 indicate whether this subcube can be considered as a surface
    return_soft_occupancy_ON: 
    if False: the gt_01 = 1 if density>1 else 0
    if True: the gt_float = density/density_inCurrentCube.max(); gt_01 = 1 if density > 0.5 else 0.
    """
    models_densityCube_param,models_densityCube = load_modellist_densityCube_aslist(params_volume.__train_set+params_volume.__val_set)
    train_gt_param, train_gt_Density = [models_densityCube_param[i] for i in params_volume.__train_set],[models_densityCube[i] for i in params_volume.__train_set]
    val_gt_param, val_gt_Density = [models_densityCube_param[i] for i in params_volume.__val_set],[models_densityCube[i] for i in params_volume.__val_set]
    
    train_gt_param, val_gt_param = np.asarray(train_gt_param).reshape(-1,params_volume.__cube_param_N), np.asarray(val_gt_param).reshape(-1,params_volume.__cube_param_N)

    normalize_keep_dim0 = lambda x : x/(np.amax(x,axis=(1,2,3),keepdims=True).astype(np.float32))
    train_gt_float = normalize_keep_dim0(np.asarray(train_gt_Density).reshape(-1,grid_D,grid_D,grid_D) )
    val_gt_float = normalize_keep_dim0(np.asarray(val_gt_Density).reshape(-1,grid_D,grid_D,grid_D))
    # train_gt_01 = np.where(train_gt_float > 0.5, 1, 0).astype(np.uint8)
    # val_gt_01 = np.where(val_gt_float > 0.5, 1, 0).astype(np.uint8)
    train_gt_01 = np.where(np.asarray(train_gt_Density).reshape(-1,grid_D,grid_D,grid_D) > 1, 1, 0).astype(np.uint8)
    val_gt_01 = np.where(np.asarray(val_gt_Density).reshape(-1,grid_D,grid_D,grid_D) > 1, 1, 0).astype(np.uint8)
    
    del models_densityCube_param,models_densityCube, train_gt_Density, val_gt_Density

    if visualization_ON:
        visualize_N_densities_pcl([train_gt_01[0],train_gt_01[100],val_gt_01[0],val_gt_01[100]])
    return train_gt_param, val_gt_param, train_gt_01, val_gt_01, train_gt_float, val_gt_float
    
    

def data_augment_rand_rotate(X_1, X_2):
    ## do the changes to the two input arrays together
    ## do the augmentation on the ending 3 axises
    # rotation augmentation: can be easily implemented by transpose + (::-1) operations
    ## randomly transpose the ending 3 axises, assume it's in 5D
    rand_Transpose = (0,1) + tuple(random.sample([2,3,4],3))
    X_1 = X_1.transpose(rand_Transpose)
    X_2 = X_2.transpose(rand_Transpose)
    ## because the axises are randomly transposed, we can do the (::-1) operation at one axis only
    X_1 = X_1[:,:,:,:,::-1]
    X_2 = X_2[:,:,:,:,::-1]
    return X_1, X_2


def data_augment_scipy_rand_rotate(X1,X2):
    """take year!!!"""
    theta1, theta2 = random.randint(0,360), random.randint(0,360)
    X1 = scipy.ndimage.interpolation.rotate(X1, theta1, axes=(-2,-1), reshape=False)
    X2 = scipy.ndimage.interpolation.rotate(X2, theta1, axes=(-2,-1), reshape=False)

    X1 = scipy.ndimage.interpolation.rotate(X1, theta2, axes=(-3,-2), reshape=False)
    X2 = scipy.ndimage.interpolation.rotate(X2, theta2, axes=(-3,-2), reshape=False)
    return X1.astype(np.float32), X2.astype(np.float32)



def data_augment_rand_crop(Xlist, crop_size = params_volume.__D_randcrop):
    # random crop on ending 3 dimensions of any tensor with grid_D>=3
    randx,randy,randz = np.random.randint(0,grid_D-crop_size+1,size=(3,))
    #[...,xxx], ... means 
    return [X[...,randx:randx+crop_size,randy:randy+crop_size,randz:randz+crop_size] for X in Xlist]
 
def data_augment_crop(Xlist, crop_size = params_volume.__D_randcrop, random_crop=True):
    # random crop on ending 3 dimensions of any tensor with grid_D>=3
    if random_crop == True:
        randx,randy,randz = np.random.randint(0,grid_D-crop_size+1,size=(3,))
    else:
        randx,randy,randz = ((grid_D-crop_size+1) / 2, ) * 3
    #[...,xxx], ... means 
    return [X[...,randx:randx+crop_size,randy:randy+crop_size,randz:randz+crop_size] if X is not None else None for X in Xlist]
 
## copied from the 1.3: from main_MVS_VGG import iterate_triplet_minibatches
def iterate_triplet_minibatches(inputs, batchsize, NOofSamples = 3):
    #batchsize = batchsize * 3
    #NOofSamples = 3 # because of triplet
    end_idx = 0    
    NOofTriplets = inputs.shape[0] / NOofSamples
    if batchsize <= NOofTriplets: 
        for start_idx in range(0, NOofTriplets - batchsize, batchsize): # don't + 1 ???
            end_idx = start_idx
            inputs_batch = inputs[NOofSamples * start_idx: NOofSamples * (start_idx + batchsize)]
            yield inputs_batch# data_augment(inputs_batch,crop_size=param.__hw_size, rand_mirror=True)
        end_idx += batchsize
    inputs_batch = inputs[NOofSamples * end_idx: ]   
    yield  inputs_batch#data_augment(inputs_batch,crop_size=param.__hw_size, rand_mirror=True)

   
    
def perform_similNet(occupiedCubes_param, view_set, N_select_viewPairs, \
         models_img, cameraPOs, cameraTs, patch_r=32, batch_size = 1000, visualization_ON=False, similNet_features_dim = 128*2+1+1, \
         similNet_fn = None, patch2feature_fn = None,featurePair2simil_fn = None, return_all0_patchPair_indicator = False,\
         return_patch_center_rgb = False, return_patchChannel_valueRange = False):
    """
    do the similarity Net's preprocess
    given params of the cube, return the selected view pairs and 
            the extracted features

    Parameters
    ----------
    similNet_fn: similarityNet's function, 
            theano.function([input_var], [feature_var, similarity])
    patch2feature_fn,featurePair2simil_fn: similarityNet's function
    occupiedCubes_param: parameters for each occupiedCubes (N,params)   
            # x,y,z,resol,modelIndx
    view_set: where the views are selected from
    N_select_viewPairs: how many view pair will be selected
    batch_size: the batch_size for the similarityNet_fn
    models_img: access img using models_img[modelIndx][viewIndx]
    cameraPOs
    cameraTs
    similNet_features_dim: dim of the return feature.
            if == 128*2+1+1: return the 2 feature vectors, dissimilarity and angle
            if == 1+1: retrn the dissimilarity and angle 
    return_all0_patchPair_indicator: take care of all-black patches (out scope patches)
            If True: only one all-0 patch go through the network to speed up
                    The all0_patchPair_indicator will be returned.
            if False: treat all the patches equally 
                    (If there will be small amount of all-black patch, this option is better)
    return_patchChannel_valueRange: if true the value range along patch_h/w will be returned
            with size of (N_pts, N_view, c) ==> (N_pts, N_viewPairs * 2, c)

    Returns
    -------
    selected_viewPairs: store the viewIndxes 
            numpy with shape (N_pts, N_select_viewPairs, 2)
    similNet_feat_dissimil_cos: includs 2 128D vectors, cos(theta), similarity value.
            this will also be used as input of the fuseNet to predict weights.
            numpy with shape (N_pts, 128*2+1+1)
    """    
    all_viewPair_viewIndx = []
    for _pairIndx in itertools.combinations(view_set,2):
        all_viewPair_viewIndx.append(_pairIndx)
    # random.shuffle(all_viewPair_viewIndx) ## So that, latter on, select the first N == randomly select N, found that there is alread rand selection scheme
    all_viewPair_viewIndx_np = np.asarray(all_viewPair_viewIndx, dtype=np.uint8)  # shape (N_randPairs,2)

    dict_viewIndx_2_dimIndx = {_viewIndx:_dimIndx for _dimIndx, _viewIndx in enumerate(view_set)}
    dict_dimIndx_2_viewIndx = {_dimIndx:_viewIndx for _dimIndx, _viewIndx in enumerate(view_set)}
    map_viewIndx_2_dimIndx_np = lambda x: np.asarray(map(dict_viewIndx_2_dimIndx.get, x.flatten())).reshape(x.shape)
    map_dimIndx_2_viewIndx_np = lambda x: np.asarray(map(dict_dimIndx_2_viewIndx.get, x.flatten())).reshape(x.shape)

    all_viewPair_dimIndx_np = map_viewIndx_2_dimIndx_np(all_viewPair_viewIndx_np)

    N_pts = occupiedCubes_param.shape[0]
    N_randPairs = len(all_viewPair_viewIndx)
    N_views = len(view_set)
    resol, modelIndx = occupiedCubes_param[0,3:5]
    # xyz of the cube center
    pts_xyz = occupiedCubes_param[:,:3] + resol * grid_D / 2 # (N_pts, 3)
    modelIndx = modelIndx.astype(np.uint16)

    unitalize_array = lambda array, _axis: array/np.linalg.norm(array, axis=_axis, ord=2, keepdims=True)
    clac_arccos = lambda cos_values: np.arccos(np.clip(cos_values, -1.0, 1.0))

    #===================
    # angle_4each_viewPair
    #===================
    # read all cameraTs into np(N_views,3)
    # TODO: change the viewIndx to dimIndx when load cameraPos/T/Img 
    cameraTs_xyz = cameraTs[view_set] # use viewIndx to access
    
    # (N_pts, 1, 3) - (1, N_views, 3) ==> (N_pts, N_views, 3)
    vector_pts2views = pts_xyz[:,None,:] - cameraTs_xyz[None,...]
    unit_vector_pts2views = unitalize_array(vector_pts2views, -1)
    # do the matrix multiplication for the (N_pats,) tack of (N_views, 3) matrixs 
    # TODO: only calc the upper diagonal part of the production is enough, because of a*a.T
    # (N_pts, N_views, 3) * (N_pts, 3, N_views) ==> (N_pts, N_views, N_views)
    cosAngles_4all_viewPairs = np.matmul(unit_vector_pts2views, unit_vector_pts2views.transpose((0,2,1)))
    angles_4all_viewPairs = clac_arccos(cosAngles_4all_viewPairs)
    # because of itertools.combinations([1,2,3],2) ==> [(1, 2), (1, 3), (2, 3)], # = C_3_2
    # only need the upper diagonal of each (N_views, N_views) maxtrix
    # get indices with size of N_views*(N_views-1)/2.
    triu_indx_dim0, triu_indx_dim1 = np.triu_indices(N_views, k=1) # Diagonal offset k=1: don't include the main diagonal
    # (N_pts, N_views, N_views) ==> (N_pts, N_views*(N_views-1)/2, 1), which will be stacked as feature along the axis=2
    angle_4unique_viewPairs = angles_4all_viewPairs[:, triu_indx_dim0.flatten(), triu_indx_dim1.flatten()][...,None]

    #===================
    # patch_on_diff_view_np and colored_patch_indicator
    #===================
    # CANNOT use [[None]*N_views]*N_pts to replace [[None for _i in range(N_views)] for _j in range(N_pts)], 
    # because the [list1,list2] are reference of each other,
    # when values in the lists will change at the same time when assign new value! 
    patch_on_diff_view = []
    colored_patch_indicator_4each_view_list = []
    # generate patches.shape=(N_pts, N_views, patch_h, patch_w, patch_c), loop over different views rather than pts.
    for _view_dimIndx, _viewIndx in enumerate(view_set):
        _patches_4this_viewIndx, patchCenter_inScope =similPrepareData.crop_imgPatch_of_3Dpt(\
                img=models_img[modelIndx][_viewIndx], projection_M=cameraPOs[_viewIndx],\
                xyz_3D=pts_xyz,patch_r=patch_r,return_PIL_or_np="np")
        patch_on_diff_view.append(_patches_4this_viewIndx[:,None,...])
        # if the patch is all 0, don't need go through the network, sign them the same feature output at one shot 
        colored_patch_indicator_4each_view_list.append(patchCenter_inScope[:,None])

    # list of np(N_pts, patch_h, patch_w, patch_c) ==> (N_pts, N_views, patch_h, patch_w, patch_c)
    patch_on_diff_view_np = np.concatenate(patch_on_diff_view, axis=1) 
    del patch_on_diff_view
    colored_patch_indicator = np.concatenate(colored_patch_indicator_4each_view_list, axis=1)
    # max along the axis(2,3) of (N_pts, N_views, patch_h, patch_w, patch_c) ==> (N_pts, N_views, patch_c)
    patchChannel_valueRange_Nview = np.amax(patch_on_diff_view_np, axis=(2,3)) - np.amin(patch_on_diff_view_np, axis=(2,3))
    # (N_pts, N_views, patch_c) ==> (N_pts, N_viewPair * 2, patch_c)
    patchChannel_valueRange = patchChannel_valueRange_Nview[:,all_viewPair_dimIndx_np.flatten(),...]
    #===================
    #
    #===================
    # this old version is only only in the train/val section, which only consider few viewPairs rather than all the viewPairs.
    if similNet_fn is not None:
        patch_on_diff_viewPair_np = patch_on_diff_view_np[:,all_viewPair_dimIndx_np.flatten(),...] # select view_dimIndx on 2nd dim [2,1,...,2,5]

        preprocessed_patch_pairs = patch_on_diff_viewPair_np.reshape((-1,)+patch_on_diff_viewPair_np.shape[-3:])
        preprocessed_patch_pairs = np.transpose(preprocessed_patch_pairs, (0,3,1,2)) # (n,h,w,c) ==> (n,c,h,w)
        preprocessed_patch_pairs = preprocessed_patch_pairs[:, ::-1, ...] # RGB ==> BGR

        similNet_dissimilar = np.array([])
        similNet_feat = []
        for batch in iterate_triplet_minibatches(preprocessed_patch_pairs, batch_size, NOofSamples = 2):
            output = similNet_fn(batch)
            similNet_feat.append(output[0])
            similNet_dissimilar = np.append(similNet_dissimilar,output[1])
        similNet_feat = np.vstack(similNet_feat).reshape((N_pts, N_randPairs, -1)) # finnal dim = 128 * 2
    # this newer version is only used in the test case, which will calculate all the viewPairs.
    # in this part of code the patch feature for each view will be only calculated once.
    # if going through all the possible view pairs (say, 1000+), this part will have 7X more speed up compared with the above old version. 
    elif (patch2feature_fn is not None) and (featurePair2simil_fn is not None):
        preprocessed_view_patches = patch_on_diff_view_np.reshape((N_pts*N_views,) + patch_on_diff_view_np.shape[-3:])
        preprocessed_view_patches = np.transpose(preprocessed_view_patches, (0,3,1,2))[:, ::-1, ...] # (n,h,w,c) ==> (n,c,h,w); RGB==>BGR
        # if return_all0_patchPair_indicator is True, selected_patchs_on_diff_view will be rewritten.
        selected_patchs_on_diff_view = preprocessed_view_patches
        # let only one all_0_patche go through the network to speed up. If there are few all0_patch, better to turn off this to speed up.
        if return_all0_patchPair_indicator:
            patch_selector = colored_patch_indicator.flatten()
            if patch_selector.min() == 0: 
                an_all0_patch_indx = patch_selector.argmin() # The selected all_0 patch's indx in the set of patches
                patch_selector[an_all0_patch_indx] = 1
                # calculate the indx of this all-0 patch in the selected set which will go through the network
                # orig=[0,1,0,1,_1_] ==> the finnal element indx4 will be indx2 in the selected set select=[1,1,_1_], 
                # so new indx2 = (orig[:indx4]).sum() 
                an_all0_patch_indx_inSelectedSet = (patch_selector[:an_all0_patch_indx]).sum()
                selected_patchs_on_diff_view = preprocessed_view_patches[patch_selector,...]

        selected_patch_feat_on_diff_views = []
        for _patch_batch in iterate_triplet_minibatches(selected_patchs_on_diff_view, batch_size, NOofSamples = 1):
            _patch_feat_batch = patch2feature_fn(_patch_batch)
            selected_patch_feat_on_diff_views.append(_patch_feat_batch)
        # stack the partial patch features
        selected_patch_feats_on_diff_views_np = np.vstack(selected_patch_feat_on_diff_views) # (N_pts*N_views, feat_dim)
        if 'an_all0_patch_indx' in dir(): # there is at least one all-0(black) patch
	    # use the only all_0_patch's feature to initialize the patch_feat_on_diff_views_np
            patch_feat_on_diff_views_np = np.repeat(selected_patch_feats_on_diff_views_np[an_all0_patch_indx_inSelectedSet][None,:],\
                    N_pts * N_views, axis=0)
            patch_feat_on_diff_views_np[patch_selector] = selected_patch_feats_on_diff_views_np
        else: # if all the patches are colored ones
            patch_feat_on_diff_views_np = selected_patch_feats_on_diff_views_np
        patch_feat_on_diff_views_np = patch_feat_on_diff_views_np.reshape((N_pts, N_views, -1)) # reshape to (N_pts, N_views, feat_dim)

        patch_feat_on_diff_viewPair_np = patch_feat_on_diff_views_np[:,all_viewPair_dimIndx_np.flatten(),...] # select view_dimIndx on 2nd dim [2,1,...,2,5]
        similNet_feat = patch_feat_on_diff_viewPair_np.reshape((N_pts, N_randPairs, -1)) # finnal dim = 128 * 2
        
        similNet_dissimilar = featurePair2simil_fn(patch_feat_on_diff_viewPair_np.reshape(N_pts*N_randPairs*2,-1))
    else:
        raise ValueError("perform_similNet need correct theano_fn inputs!")


    similNet_dissimilar = similNet_dissimilar.reshape((N_pts, N_randPairs, 1)) 

    if similNet_features_dim == 128*2+1+1:
        selected_features_array = np.concatenate([similNet_feat, similNet_dissimilar, angle_4unique_viewPairs], axis=-1).astype(np.float32) # (N_pt, N_randPairs, 128*2+1+1)
    elif similNet_features_dim == 1+1:
        selected_features_array = np.concatenate([similNet_dissimilar, angle_4unique_viewPairs], axis=-1).astype(np.float32) # (N_pt, N_randPairs, 1+1)

    if N_select_viewPairs <= 0: # return all the view pairs
        selected_randPairs = np.repeat(all_viewPair_viewIndx_np[None,...], N_pts, axis=0)
        selected_features = selected_features_array
    else:
        # only select the first N_select_viewPairs view pairs
        indic_pt, _ = np.indices((N_pts, N_randPairs))[:,:,:N_select_viewPairs] 
        indic_randPair = np.random.randint(0, N_randPairs, (N_pts, N_select_viewPairs))
        # before select the all_viewPair_viewIndx_np, should: (N_randPairs,2) --> (1, N_randPairs,2) --> (N_pt, N_randPairs,2)
        selected_randPairs = np.repeat(all_viewPair_viewIndx_np[None,...], N_pts, axis=0)[indic_pt, indic_randPair] # (N_pt, N_randPairs,2) --> (N_pt, N_select_viewPairs,2)
        selected_features = selected_features_array[indic_pt, indic_randPair] # (N_pt, N_randPairs, 128*2+1+1) --> (N_pt, N_select_viewPairs, 128*2+1+1)

    # TODO: latter should change all cameraT/Pos view ... index into dimIndx. Convert from viewIndx to dimIndx only during data loading. otherwise, too confusing
    all0_patchPair_indicator = 1 - colored_patch_indicator[:,all_viewPair_dimIndx_np.flatten(),...] # (N_pt, N_views) ==> (N_pt, N_randPairs * 2)
    all0_patchPair_indicator = all0_patchPair_indicator.reshape((N_pts,-1,2)).all(axis=-1) # (N_pts, N_randPairs * 2) ==> (N_pts, N_randPairs, 2) ==> (N_pts, N_randPairs)
    # crop the center 2 rgb pixel from each view pair's patch_pairs, then average them
    if return_patch_center_rgb:
        # treat the [patch_r, patch_r] the center pixel.
        # (N_pts, N_views, h, w, c) ==> (N_pts, N_views, c)
        patch_center_rgb_on_diff_view_np = patch_on_diff_view_np[:,:,patch_r,patch_r,:]
        # (N_pts, N_views, c) ==> (N_pts, N_viewPairs*2, c)
        patch_center_rgb_on_diff_viewPair_np_tmp = patch_center_rgb_on_diff_view_np[:,all_viewPair_dimIndx_np.flatten(),...] # select view_dimIndx on 2nd dim [2,1,...,2,5]
        # (N_pts, N_viewPairs*2, c) ==> (N_pts, N_viewPairs, c)
        patch_center_rgb_on_diff_viewPair_np = patch_center_rgb_on_diff_viewPair_np_tmp.reshape((N_pts,N_randPairs,2,3)).mean(axis=-2).astype(np.uint8)
    if return_all0_patchPair_indicator and return_patch_center_rgb and return_patchChannel_valueRange: 
        return selected_randPairs, selected_features, all0_patchPair_indicator, patch_center_rgb_on_diff_viewPair_np, patchChannel_valueRange
    else:
        return selected_randPairs, selected_features


def select_N_argmax_viewPairs(all_viewPairs, all_similNet_weight, N):
    N_pts, N_randPairs = all_viewPairs.shape[:2]
    indic_pt, _ = np.indices((N_pts, N_randPairs))[:,:,:N] 
    indic_N_max = all_similNet_weight.argsort(axis=1)[:,-1*N:]
    selected_viewPairs = all_viewPairs[indic_pt, indic_N_max]
    selected_similNet_weight = all_similNet_weight[indic_pt, indic_N_max]

    return selected_viewPairs, selected_similNet_weight

def select_M_viewPairs_from_N_randViews_for_N_samples(view_set, N_randViews, M_select_viewPairs, N_samples = 0, cubes_visib = None):
    """
    if cubes_visib is None:
        for each sample, randomly sample M viewpairs, which is combined from N random views.
    else:
        randomly select the views from the non-occluded views

    return:
        array (N_samples, M_select_viewPairs, 2)
    """
    ## N_samples = cubes_visib.shape[0] if cubes_visib is not None else N_samples
    M_viewPairs_4_N_samples = []
    for _n_sample in range(N_samples):
        if cubes_visib is None:
            # [a,b,c,d,e,f,g,h,i,j] ==> [a,b,g,c,f,e]
            N_randViews_list = random.sample(view_set, N_randViews)
        else:
            N_randViews_list = random.sample(cubes_visib[_n_sample,:,0][cubes_visib[_n_sample][:,1] == 1], N_randViews)
        # [a,b,c] ==> [(a,b),(a,c),(b,c)]
        all_pair = []
        for _pair in itertools.combinations(N_randViews_list,2):
            all_pair.append(_pair)
        
        # [(a,b),(a,c),(b,c)] ==> [(a,b),(b,c)] ==> array[[a,b],[b,c]]
        M_selected_pair_list = random.sample(all_pair, M_select_viewPairs)
        M_selected_pair_np = np.asarray(M_selected_pair_list)
        # M_selected_pair_list = [x for pair_tuple in M_selected_pair_list for x in pair_tuple] ## [(a,),(a,b),(a,b,c)] ==> [a,a,b,a,b,c]
        M_viewPairs_4_N_samples.append(M_selected_pair_np[None,...]) # shape (M_select_viewPairs,2) --> (1,M_select_viewPairs,2)

    return np.concatenate(M_viewPairs_4_N_samples) 

#----------------------------------------------------------------------            
# For test
##load_train_val_gt_asnp()
##gen_coloredCubes()
#if visualize_when_generateData_ON:
    #load_3Ddata(LowResolution=False)
##RECONSTR_generate_3DSamples_param_np(111)

